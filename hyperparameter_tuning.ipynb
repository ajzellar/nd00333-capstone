{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "gather": {
     "logged": 1598531914256
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default web browser has been opened at https://login.microsoftonline.com/organizations/oauth2/v2.0/authorize. Please continue the login in the web browser. If no web browser is available or if the web browser fails to open, use device code flow with `az login --use-device-code`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive authentication successfully completed.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name = \"compute-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print(f\"Existing Compute using {cluster_name}\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_D2_V2', max_nodes=6, min_nodes=1)\n",
    "    compute_target = ComputeTarget.create(workspace=ws, name=cluster_name, provisioning_configuration=compute_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1598531917374
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "experiment_name = 'capstone-hyperdrive'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "dataset = Dataset.get_by_name(ws, name='salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598531923519
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Hyperdrive Configuration\n",
    "\n",
    "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "gather": {
     "logged": 1598544893076
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice, uniform\n",
    "from azureml.core import Environment, ScriptRunConfig\n",
    "\n",
    "import os\n",
    "\n",
    "# TODO: Create an early termination policy. This is not required if you are using Bayesian sampling.\n",
    "early_termination_policy = BanditPolicy(slack_factor=0.15, delay_evaluation=10)\n",
    "\n",
    "#TODO: Create the different params that you will be using during training\n",
    "param_sampling = RandomParameterSampling({\n",
    "    \"--C\": choice(0.01, 0.1, 1.0, 10.0),\n",
    "    \"--max_iter\": choice(50, 100, 150, 200, 250)\n",
    "})\n",
    "\n",
    "sklearn_env = Environment.from_conda_specification(name='sklearn-env', file_path='conda_dependencies_hyperdrive.yml')\n",
    "\n",
    "estimator = ScriptRunConfig(script=\"train.py\",\n",
    "                        source_directory=\".\",\n",
    "                        environment=sklearn_env,\n",
    "                        compute_target=compute_target)\n",
    "\n",
    "hyperdrive_run_config = HyperDriveConfig(hyperparameter_sampling=param_sampling,\n",
    "                                    run_config=estimator,\n",
    "                                    policy=early_termination_policy,\n",
    "                                    primary_metric_name=\"Accuracy\",\n",
    "                                    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                    max_concurrent_runs=4,\n",
    "                                    max_total_runs=20\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gather": {
     "logged": 1598544897941
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'HD_e793d8e4-3216-48a7-9d34-63f256be0250',\n",
       " 'target': 'compute-cluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2022-05-08T22:40:44.358133Z',\n",
       " 'endTimeUtc': '2022-05-08T23:00:52.737967Z',\n",
       " 'services': {},\n",
       " 'properties': {'primary_metric_config': '{\"name\": \"Accuracy\", \"goal\": \"maximize\"}',\n",
       "  'resume_from': 'null',\n",
       "  'runTemplate': 'HyperDrive',\n",
       "  'azureml.runsource': 'hyperdrive',\n",
       "  'platform': 'AML',\n",
       "  'ContentSnapshotId': '4f5e17aa-1aef-4586-96e4-c05f87b0b3d4',\n",
       "  'user_agent': 'python/3.8.9 (macOS-10.15.7-x86_64-i386-64bit) msrest/0.6.21 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.40.0',\n",
       "  'space_size': '20',\n",
       "  'score': '0.857362198679564',\n",
       "  'best_child_run_id': 'HD_e793d8e4-3216-48a7-9d34-63f256be0250_8',\n",
       "  'best_metric_status': 'Succeeded'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://mlstrg194966.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_e793d8e4-3216-48a7-9d34-63f256be0250/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=K%2FuhIou8QKv7mSZ9w5YQc%2FbJ%2F%2FAON%2BkhBj8GXGhay8Q%3D&skoid=940331d7-2a58-4bbb-b895-7be41bcf0737&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2022-05-08T22%3A30%3A48Z&ske=2022-05-10T06%3A40%3A48Z&sks=b&skv=2019-07-07&st=2022-05-08T22%3A51%3A51Z&se=2022-05-09T07%3A01%3A51Z&sp=r'},\n",
       " 'submittedBy': 'ODL_User 194966'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train.hyperdrive import HyperDriveRun\n",
    "hd_run: HyperDriveRun = experiment.submit(hyperdrive_run_config)\n",
    "hd_run.wait_for_completion()\n",
    "# RunDetails(hd_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598544898497
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546648408
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "gather": {
     "logged": 1598546650307
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:  {'Regularization Strength:': 10.0, 'Max iterations:': 100, 'Accuracy': 0.857362198679564}\n",
      "\n",
      "\n",
      "Best run file names : ['logs/azureml/dataprep/backgroundProcess.log', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log', 'logs/azureml/dataprep/rslex.log', 'logs/azureml/dataprep/rslex.log.2022-05-08-22', 'outputs/OfflineRun_0c08ae98-773c-4110-859f-110f142d74ac_model.joblib', 'outputs/OfflineRun_4240eb40-857b-4b55-9008-6d8474db0896_model.joblib', 'outputs/OfflineRun_53e84e53-fded-48c8-a7b2-4bd175523904_model.joblib', 'outputs/OfflineRun_710cf2d5-ff0c-47b1-b837-cd38acb6fe32_model.joblib', 'outputs/OfflineRun_7cd92f43-62d1-4556-afba-87d17b182bf6_model.joblib', 'outputs/OfflineRun_87fe93a0-744c-43ee-acc6-4ab8e2b2ede9_model.joblib', 'outputs/OfflineRun_b62c83d5-6571-4e87-83b0-9613fa40a340_model.joblib', 'outputs/OfflineRun_d804e689-26aa-4bdc-b8f5-dcc495c3f796_model.joblib', 'outputs/model.joblib', 'system_logs/cs_capability/cs-capability.log', 'system_logs/hosttools_capability/hosttools-capability.log', 'system_logs/lifecycler/execution-wrapper.log', 'system_logs/lifecycler/lifecycler.log', 'user_logs/std_log.txt']\n",
      "\n",
      "\n",
      "Run Id: HD_e793d8e4-3216-48a7-9d34-63f256be0250_8 Accuracy: 0.857362198679564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model.joblib'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from azureml.core.model import Model\n",
    "os.makedirs(\"./outputs\", exist_ok=True)\n",
    "best_run = hd_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "best_run_file_names = best_run.get_file_names()\n",
    "print('Metrics: ', best_run_metrics)\n",
    "print(\"\\n\\nBest run file names :\", best_run_file_names)\n",
    "print('\\n\\nRun Id: {} Accuracy: {}'.format(best_run.id, best_run_metrics['Accuracy']))\n",
    "# model_path = \"./outputs/{}_model.joblib\".format(best_run.id)\n",
    "final_model: Model = best_run.register_model(model_name = 'hyperdrive_model',model_path = \"./outputs/model.joblib\")\n",
    "final_model.download(\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546657829
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Save the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model hyperdrive_model:2 to /var/folders/15/lvlk9w416qz37f4c1w7k5s7c4pgff9/T/azureml_qo_41rid/hyperdrive_model/2\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry 7f447ae3207f4d1585cf53c3ec74893d.azurecr.io\n",
      "Logging into Docker registry 7f447ae3207f4d1585cf53c3ec74893d.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM 7f447ae3207f4d1585cf53c3ec74893d.azurecr.io/azureml/azureml_0411c2f901f3867c64dbfc5754860b61\n",
      " ---> 97b4d57e5053\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 3b834d9045f4\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjlhNzUxMWI4LTE1MGYtNGE1OC04NTI4LTNlN2Q1MDIxNmMzMSIsInJlc291cmNlR3JvdXBOYW1lIjoiYW1sLXF1aWNrc3RhcnRzLTE5NDk2NiIsImFjY291bnROYW1lIjoicXVpY2stc3RhcnRzLXdzLTE5NDk2NiIsIndvcmtzcGFjZUlkIjoiN2Y0NDdhZTMtMjA3Zi00ZDE1LTg1Y2YtNTNjM2VjNzQ4OTNkIn0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in 81afc29af179\n",
      " ---> 3793e70b64d3\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpezaowms3.py' /var/azureml-app/main.py\n",
      " ---> Running in 6d4274154159\n",
      " ---> 2ed0e5b8d043\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 4084fda02a28\n",
      " ---> 12efe971c338\n",
      "Successfully built 12efe971c338\n",
      "Successfully tagged hdmodelservice:latest\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:2be769a7b4a31dfdb8ff131d769acd8b7700a5c3f647c1b85dea4a1fa91e3229 successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:6789\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core import Environment\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.webservice import AciWebservice, LocalWebservice\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    environment=sklearn_env,\n",
    "    source_directory=\".\",\n",
    "    entry_script=\"./score.py\"\n",
    ")\n",
    "\n",
    "# deployment_config = AciWebservice.deploy_configuration(\n",
    "#     cpu_cores=0.5, memory_gb=1, auth_enabled=True\n",
    "# )\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6789)\n",
    "\n",
    "\n",
    "service = Model.deploy(\n",
    "    ws,\n",
    "    \"hdmodelservice\",\n",
    "    [final_model],\n",
    "    inference_config,\n",
    "    deployment_config,\n",
    "    overwrite=True,\n",
    ")\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test is {'query': 'What color is the fox', 'context': 'The quick brown fox jumped over the lazy dog.'}\n",
      "2022-05-07T16:44:02,618171100+00:00 - gunicorn/run \n",
      "2022-05-07T16:44:02,618151600+00:00 - iot-server/run \n",
      "Dynamic Python package installation is disabled.\n",
      "Starting HTTP server\n",
      "2022-05-07T16:44:02,619041400+00:00 - rsyslog/run \n",
      "2022-05-07T16:44:02,624185500+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2022-05-07T16:44:02,765203700+00:00 - iot-server/finish 1 0\n",
      "2022-05-07T16:44:02,766644300+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (13)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 43\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2022-05-07 16:44:03,557 | root | INFO | Starting up app insights client\n",
      "logging socket was found. logging is available.\n",
      "logging socket was found. logging is available.\n",
      "2022-05-07 16:44:03,557 | root | INFO | Starting up request id generator\n",
      "2022-05-07 16:44:03,557 | root | INFO | Starting up app insight hooks\n",
      "2022-05-07 16:44:03,558 | root | INFO | Invoking user's init function\n",
      "['nd00333-capstone', 'azureml-models', 'main.py', 'model_config_map.json']\n",
      "no request id,['nd00333-capstone', 'azureml-models', 'main.py', 'model_config_map.json']\n",
      "\n",
      "['model.joblib']\n",
      "no request id,['model.joblib']\n",
      "\n",
      "2022-05-07 16:44:04,125 | root | INFO | Users's init has completed successfully\n",
      "2022-05-07 16:44:04,128 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2022-05-07 16:44:04,128 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2022-05-07 16:44:04,130 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "2022-05-07 16:58:33,402 | root | INFO | Scoring Timer is set to 3600.0 seconds\n",
      "received data {}\n",
      "64176894-331d-41ab-ad78-0d489424b898,received data {}\n",
      "\n",
      "2022-05-07 16:58:33,403 | root | INFO | 200\n",
      "127.0.0.1 - - [07/May/2022:16:58:33 +0000] \"GET /score HTTP/1.0\" 200 12 \"-\" \"python-requests/2.27.1\"\n",
      "2022-05-07 16:58:33,413 | root | INFO | Scoring Timer is set to 3600.0 seconds\n",
      "received data {'query': 'What color is the fox', 'context': 'The quick brown fox jumped over the lazy dog.'}\n",
      "6ff0f5ac-33c5-4c43-a8e9-0bf60f9c834e,received data {'query': 'What color is the fox', 'context': 'The quick brown fox jumped over the lazy dog.'}\n",
      "\n",
      "2022-05-07 16:58:33,414 | root | INFO | 200\n",
      "127.0.0.1 - - [07/May/2022:16:58:33 +0000] \"POST /score HTTP/1.0\" 200 104 \"-\" \"python-requests/2.27.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from score import process_input\n",
    "import pandas as pd\n",
    "\n",
    "# uri = service.scoring_uri\n",
    "# requests.get(uri)\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "data = {\n",
    "    \"age\": 25,\n",
    "    \"workclass\": \"Private\",\n",
    "    \"fnlwgt\": 176756,\n",
    "    \"education\": \"Masters\",\n",
    "    \"education-num\": 14,\n",
    "    \"marital-status\": \"Never-married\",\n",
    "    \"occupation\": \"Sales\",\n",
    "    \"sex\": \"Female\",\n",
    "    \"capital-gain\": 0,\n",
    "    \"capital-loss\": 0,\n",
    "    \"hours-per-week\": 45,\n",
    "    \"native-country\": \"United-States\"\n",
    "}\n",
    "dft = pd.DataFrame(data)\n",
    "dft.head()\n",
    "# data = json.dumps(data)\n",
    "# response = requests.post(uri, data=data, headers=headers)\n",
    "# print(response.json())\n",
    "# print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission Checklist**\n",
    "- I have registered the model.\n",
    "- I have deployed the model with the best accuracy as a webservice.\n",
    "- I have tested the webservice by sending a request to the model endpoint.\n",
    "- I have deleted the webservice and shutdown all the computes that I have used.\n",
    "- I have taken a screenshot showing the model endpoint as active.\n",
    "- The project includes a file containing the environment details.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
